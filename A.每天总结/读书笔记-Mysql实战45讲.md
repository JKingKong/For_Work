# 01 | 基础架构：一条SQL查询语句是如何执行的？

1. SQL查询语句的执行过程
2. Mysql的结构和运行过程

# 02 | 日志系统：一条SQL更新语句是如何执行的？

1. 一条更新语句的执行流程又是怎样的呢？
2. redo log日志（物理）：记录这个页 “做了什么改动”
3. binlog日志（逻辑）
4. 在有日志的情况下SQL更新语句的执行过程
5. 如何让数据库恢复到半个月内的任一秒状态？
6. 两阶段提交是什么？为什么要有两段提交？
   1. 两阶段提交：prepare、commit （感觉像事务，要么redo log、binlog都成功，幺妹都失败）
   2. 两种假想情况
      1. 如果先写 redo log 后写 binlog的情况
      2. 如果先写 binlog 后写 redo log
   3. 两阶段提交使得redo log和binlog在状态上保持一致，可以使得横向扩展数据库时保持数据库数据的一致性
7. 一些思考：
   1. redo log 在commit时 crash怎么办？
   2. 定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？ 
   3. redo log已经可以实现复制、保存状态，binlog是否是多余的？
   4. redo log只有4个g，binlog全量，如何保证4个g以外部分也一致呢？
      1. 事务提交时刷盘，满了的时候刷盘
   5. 一个事务怎么知道自身在redo log中prepare成功时在binlog中是成功的？
   6. 刷脏页问题导致Mysql性能降低
      1. 场景1：redo log写满了，此时MySQL会停止所有更新操作，把脏页刷到磁盘
      2. 场景2：系统内存不足，需要将脏页淘汰，此时会把脏页刷到磁盘
      3. 场景3：系统空闲时，MySQL定期将脏页刷到磁盘 （不会）

# 03 | 事务隔离：为什么你改了我还看不见？

## ACID中的 I

1. 并发的两个事务

   ![img](images/7dea45932a6b722eb069d2264d0066f8-1584778526408.png)

   * 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。
   * 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。
   * 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
   * 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。

## 事务隔离的实现

1. 可重复读的实现
   1. MVCC、read-view概念
   2. 回滚日志什么时候删除？
2. 尽量避免长事务，长事务可能会造成回滚段非常长（回滚日志非常大）

## 事务的启动方式

1. 

## 小结

1. 务的特性：原子性、一致性、隔离性、持久性
2. 多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读
3. 事务隔离级别：读未提交、读提交、可重复读、串行化
4. 不同事务隔离级别的区别：
   读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到
   读提交：一个事务提交之后，它所做的变更才可以被别的事务看到
   可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的
   串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行
5. 配置方法：启动参数transaction-isolation
6. **事务隔离的实现**：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。
7. **回滚日志什么时候删除？**
   1. 系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。
8. 什么时候不需要了？
   1. 当系统里么有比这个回滚日志更早的read-view的时候。
9. 为什么尽量不要使用长事务。
   1. 长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。
10. **事务启动方式：**
    1. 显式启动事务语句，begin或者start transaction，提交commit，回滚rollback；
    2. set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接。
    3. 建议使用方法一，如果考虑多一次交互问题，可以使用commit work and chain语法。在autocommit=1的情况下用begin显式启动事务，如果执行commit则提交事务。如果执行commit work and chain则提交事务并自动启动下一个事务。

思考题：

​	在开发过程中，尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用，并且支持动态日志空间增长。监控Innodb_trx表，发现长事务报警。

## 问题

### 如何避免长事务对业务的影响？

首先，从应用开发端来看：

1. **确认是否使用了 set autocommit=0**。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种**只读事务可以去掉**。
3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来**控制每个语句执行的最长时间，避免单个语句意外执行太长时间**。（为什么会意外？在后续的文章中会提到这类案例）

其次，从数据库端来看：

1. 监控 information_schema.Innodb_trx 表，设置**长事务阈值**，超过就报警 / 或者 kill；
2. Percona 的 **pt-kill 这个工具**不错，推荐使用；
3. 在业务功能测试阶段要求输出所有的 **general_log**，分析日志行为提前发现问题；
4. 如果使用的是 MySQL  5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

# 04 | 深入浅出索引（上）

## 索引常见模型

1. 哈希表

2. 有序数组（适合静态存储引擎，即：那些数据不会变的，比如2017年某个城市的所有人口信息这种已经成为历史的数据）

3. 平衡二叉树

4. N叉树

5. B+树

   ## Innodb的索引模型

   1. B+树
   2. 主键索引和非主键索引  
      1. 别称：聚簇索引和非聚簇索引 （二级索引）
   3. 基于主键索引和普通索引的查询有什么区别？
   4. 索引维护
      1. 插入新数据索引维护的页分裂问题
      2. 自动自增主键的优点
      3. 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

## 问题

1. 对于上面例子中的 InnoDB 表 T，如果你要**重建索引 k**，你的两个 SQL 语句可以这么写：

```sql
alter table T drop index k;
alter table T add index(k);
```

如果你要**重建主键索**引，也可以这么写：

```sql
alter table T drop primary key;
alter table T add primary key(id);
```

问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

​		**重建索引 k** 的做法是**合理**的，可以达到省空间的目的。

​		但是，**重建主键**的过程**不合理**。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。在专栏的第 12 篇文章《为什么表数据删掉一半，表文件大小不变？》中，我会和你分析这条语句的执行流程。

2. 为什么要重建索引？

​		索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。

3. 插入数据时，是否每个索引都需要去维护？

答案：是的，索引越多，“维护成本”越大

4. 

# 05 | 深入浅出索引（下）

## 使用非聚簇索引的SQL语句查询过程

### 回表

回到主键索引树搜索的过程，我们称为回表

## 覆盖索引

查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

### 案例：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？

1. 只需要查询身份证号：不需要建立
2. 需要查询身份证号和姓名（业务中出现的频率十分高）：需要建立



## 最左前缀原则

### 什么是最左匹配原则

1. B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。

2. ```sql
   //可以使用索引，
   select * from A where name = "张%"
   //不可以使用索引
   select * from A where name =  "%张" 
   ```

### 联合索引

#### 在建立联合索引的时候，如何安排索引内的字段顺序。

1. 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。（索引选择性）
2. 第二个考虑的原则就是空间

### 索引下推

最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？

我们还是以市民表的联合索引（name， age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：

```sql
mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
```

1. 无索引下推：在索引查询到“张xx”时，**不会利用索引**“age = 10”来排除一些绝对不符合查询的项，要全部对"张xx"进行回表查询，因此回表次数可能较多
2. 索引下推：在索引查询到“张xx”时，**会利用索引**“age = 10”来**排除**一些绝对不符合查询的项，以减少回表次数

### 问题

​	    实际上主键索引也是可以使用多个字段的。DBA 小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：

```sql
CREATE TABLE `geek` (
  `a` int(11) NOT NULL，
  `b` int(11) NOT NULL，
  `c` int(11) NOT NULL，
  `d` int(11) NOT NULL，
  PRIMARY KEY (`a`，`b`)，
  KEY `c` (`c`)，
  KEY `ca` (`c`，`a`)，
  KEY `cb` (`c`，`b`)
) ENGINE=InnoDB;
```

​		公司的同事告诉他说，由于历史原因，这个表需要 a、b 做联合主键，这个小吕理解了。

​		但是，学过本章内容的小吕又纳闷了，既然主键包含了 a、b 这两个字段，那意味着单独在字段 c 上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？同事告诉他，是因为他们的业务里面有这样的两种语句：

```sql
select * from geek where c=N order by a limit 1;
select * from geek where c=N order by b limit 1;
```

​		我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？

**答：**

表记录

–a--|–b--|–c--|–d--

1 2 3 d

1 3 2 d

1 4 3 d

2 1 3 d

2 2 2 d

2 3 4 d

主键 a，b 的聚簇索引组织顺序相当于 order by a，b ，也就是先按 a 排序，再按 b 排序，c 无序。

索引 ca 的组织是先按 c 排序，再按 a 排序，**同时记录主键**

–c--|–a--|–主键部分b-- （注意，这里不是 ab，而是只有 b）

2 1 3

2 2 2

3 1 2

3 1 4

3 2 1

4 2 3这个跟索引 c 的数据是一模一样的。

索引 cb 的组织是先按 c 排序，在按 b 排序，**同时记录主键**

–c--|–b--|–主键部分a-- （同上）

2 2 2

2 3 1

3 1 2

3 2 1

3 4 1

4 3 2

结论：**是 ca 可以去掉，cb 需要保留**（因为ca可以先查cb前缀匹配，而后主键索引a，组合效果可以得到：ca）。

# 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

## 锁

### 全局锁

整个数据库实例都被锁 上，变成**只读**

使用场景：全局锁的典型使用场景是，做**全库逻辑备份**

#### 备份为什么要加锁呢？我们来看一下不加锁会有什么问题。

1. 不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。

2. 有了single-transaction，为什么还需要FTWRL？

   1. 一致性读是好，但前提是引擎**要支持**这个**隔离级别**。比如，对于 **MyISAM** 这种**不支持事务**的引擎，因此还是需要FTWRL

      （对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。）

3. 既然要全库只读，为什么不使用 set global readonly=true 的方式呢？

   1. 在有些系统中，**readonly** 的值会被用来做其他逻辑，比如用来**判断**一个库是**主库**还是**备库**。因此，修改 global 变量的方式影响面更大，我不建议你使用

4. 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

   ### 表级锁

   #### 表锁

   01 | 基础架构：一条SQL查询语句是如何执行的？

   1. SQL查询语句的执行过程
   2. Mysql的结构和运行过程

   # 02 | 日志系统：一条SQL更新语句是如何执行的？

   1. 一条更新语句的执行流程又是怎样的呢？
   2. redo log日志（物理）：记录这个页 “做了什么改动”
   3. binlog日志（逻辑）
   4. 在有日志的情况下SQL更新语句的执行过程
   5. 如何让数据库恢复到半个月内的任一秒状态？
   6. 两阶段提交是什么？为什么要有两段提交？
      1. 两阶段提交：prepare、commit （感觉像事务，要么redo log、binlog都成功，幺妹都失败）
      2. 两种假想情况
         1. 如果先写 redo log 后写 binlog的情况
         2. 如果先写 binlog 后写 redo log
      3. 两阶段提交使得redo log和binlog在状态上保持一致，可以使得横向扩展数据库时保持数据库数据的一致性
   7. 一些思考：
      1. redo log 在commit时 crash怎么办？
      2. 定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？ 
      3. redo log已经可以实现复制、保存状态，binlog是否是多余的？
      4. redo log只有4个g，binlog全量，如何保证4个g以外部分也一致呢？
         1. 事务提交时刷盘，满了的时候刷盘
      5. 一个事务怎么知道自身在redo log中prepare成功时在binlog中是成功的？
      6. 刷脏页问题导致Mysql性能降低
         1. 场景1：redo log写满了，此时MySQL会停止所有更新操作，把脏页刷到磁盘
         2. 场景2：系统内存不足，需要将脏页淘汰，此时会把脏页刷到磁盘
         3. 场景3：系统空闲时，MySQL定期将脏页刷到磁盘 （不会）

   # 03 | 事务隔离：为什么你改了我还看不见？

   ## ACID中的 I

   1. 并发的两个事务

      ![img](../A.%E6%AF%8F%E5%A4%A9%E6%80%BB%E7%BB%93/images/7dea45932a6b722eb069d2264d0066f8-1584778526408.png)

      - 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。
      - 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。
      - 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
      - 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。

   ## 事务隔离的实现

   1. 可重复读的实现
      1. MVCC、read-view概念
      2. 回滚日志什么时候删除？
   2. 尽量避免长事务，长事务可能会造成回滚段非常长（回滚日志非常大）

   ## 事务的启动方式

   1. 

   ## 小结

   1. 务的特性：原子性、一致性、隔离性、持久性
   2. 多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读
   3. 事务隔离级别：读未提交、读提交、可重复读、串行化
   4. 不同事务隔离级别的区别：
      读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到
      读提交：一个事务提交之后，它所做的变更才可以被别的事务看到
      可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的
      串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行
   5. 配置方法：启动参数transaction-isolation
   6. **事务隔离的实现**：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。
   7. **回滚日志什么时候删除？**
      1. 系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。
   8. 什么时候不需要了？
      1. 当系统里么有比这个回滚日志更早的read-view的时候。
   9. 为什么尽量不要使用长事务。
      1. 长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。
   10. **事务启动方式：**
       1. 显式启动事务语句，begin或者start transaction，提交commit，回滚rollback；
       2. set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接。
       3. 建议使用方法一，如果考虑多一次交互问题，可以使用commit work and chain语法。在autocommit=1的情况下用begin显式启动事务，如果执行commit则提交事务。如果执行commit work and chain则提交事务并自动启动下一个事务。

   思考题：

   ​	在开发过程中，尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用，并且支持动态日志空间增长。监控Innodb_trx表，发现长事务报警。

   ## 问题

   ### 如何避免长事务对业务的影响？

   #### 首先，从应用开发端来看：

   1. **确认是否使用了 set autocommit=0**。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。
   2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种**只读事务可以去掉**。
   3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来**控制每个语句执行的最长时间，避免单个语句意外执行太长时间**。（为什么会意外？在后续的文章中会提到这类案例）

   #### 其次，从数据库端来看：

   1. 监控 information_schema.Innodb_trx 表，设置**长事务阈值**，超过就报警 / 或者 kill；
   2. Percona 的 **pt-kill 这个工具**不错，推荐使用；
   3. 在业务功能测试阶段要求输出所有的 **general_log**，分析日志行为提前发现问题；
   4. 如果使用的是 MySQL  5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

   # 04 | 深入浅出索引（上）

   ## 索引常见模型

   1. 哈希表

   2. 有序数组（适合静态存储引擎，即：那些数据不会变的，比如2017年某个城市的所有人口信息这种已经成为历史的数据）

   3. 平衡二叉树

   4. N叉树

   5. B+树

      ## Innodb的索引模型

      1. B+树
      2. 主键索引和非主键索引  
         1. 别称：聚簇索引和非聚簇索引 （二级索引）
      3. 基于主键索引和普通索引的查询有什么区别？
      4. 索引维护
         1. 插入新数据索引维护的页分裂问题
         2. 自动自增主键的优点
         3. 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

   ## 问题

   1. 对于上面例子中的 InnoDB 表 T，如果你要**重建索引 k**，你的两个 SQL 语句可以这么写：

   ```sql
   alter table T drop index k;
   alter table T add index(k);
   ```

   如果你要**重建主键索**引，也可以这么写：

   ```sql
   alter table T drop primary key;
   alter table T add primary key(id);
   ```

   问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

   ​		**重建索引 k** 的做法是**合理**的，可以达到省空间的目的。

   ​		但是，**重建主键**的过程**不合理**。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。在专栏的第 12 篇文章《为什么表数据删掉一半，表文件大小不变？》中，我会和你分析这条语句的执行流程。

   2. 为什么要重建索引？

   ​		索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。

   3. 插入数据时，是否每个索引都需要去维护？

   答案：是的，索引越多，“维护成本”越大

   4. 

   # 05 | 深入浅出索引（下）

   ## 使用非聚簇索引的SQL语句查询过程

   ### 回表

   回到主键索引树搜索的过程，我们称为回表

   ## 覆盖索引

   查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

   **由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

   ### 案例：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？

   1. 只需要查询身份证号：不需要建立
   2. 需要查询身份证号和姓名（业务中出现的频率十分高）：需要建立

   

   ## 最左前缀原则

   ### 什么是最左匹配原则

   1. B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。

   2. ```sql
      //可以使用索引，
      select * from A where name = "张%"
      //不可以使用索引
      select * from A where name =  "%张" 
      ```

   ### 联合索引

   #### 在建立联合索引的时候，如何安排索引内的字段顺序。

   1. 第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。（索引选择性）
   2. 第二个考虑的原则就是空间

   ### 索引下推

   最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？

   我们还是以市民表的联合索引（name， age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：

   ```sql
   mysql> select * from tuser where name like '张%' and age=10 and ismale=1;
   ```

   1. 无索引下推：在索引查询到“张xx”时，**不会利用索引**“age = 10”来排除一些绝对不符合查询的项，要全部对"张xx"进行回表查询，因此回表次数可能较多
   2. 索引下推：在索引查询到“张xx”时，**会利用索引**“age = 10”来**排除**一些绝对不符合查询的项，以减少回表次数

   # 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

   ## 锁

   ### 全局锁

   整个数据库实例都被锁 上，变成**只读**

   使用场景：全局锁的典型使用场景是，做全库逻辑备份

   #### 备份为什么要加锁呢？我们来看一下不加锁会有什么问题。

   1. 不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。
   2. 有了single-transaction，为什么还需要FTWRL？
      1. 一致性读是好，但前提是引擎**要支持**这个**隔离级别**。比如，对于 **MyISAM** 这种**不支持事务**的引擎，因此还是需要FTWRL
   3. 既然要全库只读，为什么不使用 set global readonly=true 的方式呢？
      1. 在有些系统中，**readonly** 的值会被用来做其他逻辑，比如用来**判断**一个库是**主库**还是**备库**。因此，修改 global 变量的方式影响面更大，我不建议你使用
   4. 在异常处理机制上有差异。如果执行 **FTWRL 命令**之后由于**客户端发生异常断开，那么 MySQL 会自动释放这个全局锁**，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。

### 表级锁

#### 表锁

显式加锁表锁的语法是 lock tables … read/write。

#### 元数据锁MDL（metadata lock)

不需要显式使用，

* **读锁之间不互斥**，因此你可以有多个线程同时对一张表增删改查。
* **读写锁之间、写锁之间是互斥**的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

##### 案例

**给一个小表加个字段，导致整个库挂了。**

1. session A读锁
2. session B读锁
3. session C写锁，阻塞 (导致下边的读锁申请阻塞，若查询语句频繁，库线程会爆满)
4. session D读锁，阻塞
5. session E读锁，阻塞
6. ....，阻塞

**如何安全地给小表加字段？**

1. 首先我们要解决长事务，增加字段的事务不提交，就会一直占着 MDL 锁。（kill掉长事务）
2. 如果请求过于频繁，kill可能失效，该怎么办？
   1. 在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。

### 问题

1. 备份一般都会在备库上执行，你在用–single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？

假设这个 DDL 是针对表 t1 的， 这里我把备份过程中几个关键的语句列出来：

```sql
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```

语句解释：

在备份开始的时候，为了确保 RR（可重复读）隔离级别，再设置一次 RR 隔离级别 (Q1);

启动事务，这里用 WITH CONSISTENT SNAPSHOT 确保这个语句执行完就可以得到一个一致性视图（Q2)；

设置一个保存点，这个很重要（Q3）；

show create 是为了拿到表结构 (Q4)，然后正式导数据 （Q5），回滚到 SAVEPOINT sp，在这里的作用是释放 t1 的 MDL 锁 （Q6）。当然这部分属于“超纲”，上文正文里面都没提到。

DDL 从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。

参考答案：

1. 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。
2. 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed， please retry transaction，现象：mysqldump 终止；
3. 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。
4. 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构。

# 07 | 行锁功过：怎么减少行锁对性能的影响？



## 	两阶段锁协议

**什么是两阶段锁协议？**

​		在 InnoDB 事务中，行锁是在**需要的时候才加上的（当使用到时加锁）**，但并不是不需要了就立刻释放，而是要等到**事务结束时才释放**。这个就是两阶段锁协议

**知道了这个设定，对我们使用事务有什么帮助呢？**

​		如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放，这样就能**晚一点加锁**，从而**减少锁的竞争**

## 死锁和死锁检测

### 应对死锁的策略

* 一种策略是，直接进入**等待**，直到**超时**。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。（默认：50s）
* 另一种策略是，**发起死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。（高并发下死锁检测**消耗极大的资源**）

### 如何解决高并发下热点行更新导致的性能问题呢？

1. 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
2. 另一个思路是控制并发度。
   1. 修改Mysql源码：基本思路就是，对于相同行的更新，在进入引擎之前排队。
   2. 通过将一行改成逻辑上的多行来减少锁冲突。例如：比如 10 个行记录，影院的账户总额等于这 10 个行记录的值的总和（这样无形之中增加了并发度，但是要注意退票减少到0时的程序逻辑处理）

## 问题

1. 如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：

* 第一种，直接执行 delete from T limit 10000;
* **第二种，在一个连接中循环执行 20 次 delete from T limit 500;**
* 第三种，在 20 个连接中同时执行 delete from T limit 500。

参考答案：

​		第二种方式相对较好的，即：在一个连接中循环执行 20 次 delete from T limit 500。

​		第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。

​		第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。

# 08 | 事务到底是隔离的还是不隔离的？

## “快照”在 MVCC 里是怎么工作的？

1. **一致性视图**（consistent read view）实现事务的读提交（RC）和重复读（RR）
2. 事务在启动时会拍一个快照，这个快照是**基于整个库**的
   1. **基于整个库**的意思就是说一个事务内，整个库的**修改**对于**该事务**都是**不可见的**(对于快照读的情况)，如果在事务内select t表，另外的事务执行了DDL t表，根据发生时间，要嘛锁住要嘛报错(参考第六章)
3. 事务是如何实现的MVCC呢?
   1. 每个事务都有一个事务ID，叫做transaction id（严格递增）
   2. 事务在更新一条语句时，比如id=1改为了id=2.会把id=1和该行之前的row trx_id写到undo log里，并且在数据页上把id的值改为2，并且把修改这条语句的transaction id记在该行行头
   3. 再定一个规矩，一个事务要查看一条数据时，必须先用该事务的up_limit_id与该行的transaction id做比对
      1. 如果transaction id  <= up_limit_id ，那么可以看。
      2. 如果up_limit_id < transaction id，则只能去undo log里去取。去undo log查找数据的时候，也需要做比对，必须up_limit_id > transaction id，才返回数据
4. “**当前读**”：**更新数据**都是**先读后写**的，而这个读，只能读当前的值，称为“当前读”（current read）
5. 为什么RR能实现可重复读而RC不能，分两种情况
   1. **快照读**的情况下，RR不能更新事务内的up_limit_id，而RC每次会把up_limit_id更新为快照读之前最新已提交事务的transaction id，则RC不能可重复读
   2. **当前读**的情况下，RR是利用record lock + gap lock来实现的，而RC没有gap，所以RC不能可重复读

## 问题

​		我用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段 c 和 id 值相等的行”的 c 值清零，但是却发现了一个“诡异”的、改不掉的情况。请你构造出这种情况，并说明其原理。

```sql
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);
```

![img](images/9b8fe7cf88c9ba40dc12e93e36c3060b.png)

​		复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？